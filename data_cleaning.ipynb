{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c32510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.data_extraction import print_nan_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcf4491",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2008-01-02\"\n",
    "end_date = '2022-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4282aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_extraction import get_top_indian_stocks_tickers\n",
    "from src.data_extraction import batch_download_price_data\n",
    "\n",
    "tickers = get_top_indian_stocks_tickers()\n",
    "df = batch_download_price_data(tickers, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f015c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = Indian_stocks_df(start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f579b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"datas/raw_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3977b474",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The length of the raw data set: ',df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aa824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_nan_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3427c68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_summary = (\n",
    "    df.isna()\n",
    "      .sum()\n",
    "      .loc[lambda x: x > 100]\n",
    "      .to_frame(name=\"nan_count\")\n",
    ")\n",
    "nan_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4840cab0",
   "metadata": {},
   "source": [
    "We see that there are many stocks that have empty data, we cannot remove them irresposibly because we will loose importamt information. We could start by keeping stocks that have atleast 90% of data available and then we could fill the empty data points with the previous values. But, we are carful here also to only fill atmost 3 consecutive data points with the prvious values, this is because if we are dealing withstocks that did not have an IPO before a time period or it got delisted after some time then filling without limit will cause us to have long periods of time with same price leading to wrong results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a7de04",
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage = df.notna().mean()\n",
    "\n",
    "keep_cols = coverage[coverage > 0.9].index\n",
    "df = df[keep_cols]\n",
    "\n",
    "df = df.ffill(limit=3)\n",
    "\n",
    "print(\"The shape of the dataframe is:\",df.shape)\n",
    "print_nan_summary(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee88f9d",
   "metadata": {},
   "source": [
    "Okay apart from the data we removed we only have 13 columns with empty data points <= 10 % we could remove these stocks and do our analysis because we are still left with more than a 100 stocks which will still provide us with good insights without the unnessecary complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087fe437",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_counts = df.isna().sum()\n",
    "nan_cols = nan_counts[nan_counts >= 1]\n",
    "\n",
    "print(nan_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581dcf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=1)\n",
    "print_nan_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da33199f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The length of the cleaned data set: ',df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3dac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"datas/clean_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e463a3e",
   "metadata": {},
   "source": [
    "We, want to work with the log returns because of it is approximately normally distributed and using the symmetric and additive property of log returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496b6610",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = np.log(df/df.shift())\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c12af43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('datas/log_returns_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
